const LLM_Blurb_List = ["A large language model (LLM) is a language model characterized by its large size.",
"LLMs are artificial neural networks which can contain a billion to trillion of weights, and are (pre-)trained using self-supervised learning and semi-supervised learning.",
"Transformer architecture contributed to faster training.",
"As language models, they work by taking an input text and repeatedly predicting the next token or word.",
"Larger sized models, such as GPT-3, however, can be prompt-engineered to achieve similar results.",
"They are thought to acquire embodied knowledge about syntax, semantics and 'ontology' inherent in human language corpora, but also inaccuracies and biases present in the corpora.",
"Notable examples include OpenAI's GPT models (e.g., GPT-3.5 and GPT-4, used in ChatGPT), Google's PaLM (used in Bard), and Meta's LLaMa, as well as BLOOM, Ernie 3.0 Titan, and Claude.",
"Using a modification of byte-pair encoding, in the first step, all unique characters (including blanks and punctuation marks) are treated as an initial set of n-grams (i.e. initial set of uni-grams).",
"Probabilistic tokenization also compresses the datasets, which is the reason for using the byte pair encoding algorithm as a tokenizer.",
"Removal of toxic passages from the dataset, discarding low-quality data, and de-duplication are examples of dataset cleaning.", "Using 'self-instruct' approaches, LLMs have been able to bootstrap correct responses, replacing any naive responses, starting from human-generated corrections of a few cases.",
"Most results previously achievable only by (costly) fine-tuning, can be achieved through prompt engineering, although limited to the scope of a single conversation.",
"In order to find out which tokens are relevant to each other within the scope of the context window, the attention mechanism calculates 'soft' weights for each token, more precisely for its embedding, by using multiple attention heads, each with its own 'relevance' for calculating its own soft weights.", 
"The largest models can have a context window sized up to 32k (for example, GPT-4; while GPT-3.5 has a context window sized from 4k to 16k, and legacy GPT-3 has had 2k sized context window).", "Length of a conversation that the model can take into account when generating its next answer is limited by the size of a context window, as well.", 
"The shortcomings of making a context window larger include higher computational cost and possibly diluting the focus on local context, while making it smaller can cause a model to miss an important long-range dependency. Balancing them are a matter of experimentation and domain-specific considerations.", 
"A model may be pre-trained either to predict how the segment continues, or what is missing in the segment, given a segment from its training dataset.", "Models may be trained on auxiliary tasks which test their understanding of the data distribution, such as Next Sentence Prediction (NSP), in which pairs of sentences are presented and the model must predict whether they appear consecutively in the training corpus.", 
"Advances in software and hardware have reduced the cost substantially since 2020, such that in 2023 training of a 12-billion-parameter LLM computational cost is 72,300 A100-GPU-hours, while in 2020 the cost of training a 1.5-billion-parameter LLM (which was two orders of magnitude smaller than the state of the art in 2020) was between $80 thousand and $1.6 million.", 
"There are certain tasks that, in principle, cannot be solved by any LLM, at least not without the use of external tools or additional software. An example of such a task is responding to the user's input '354 * 139 = ', provided that the LLM has not already encountered a continuation of this calculation in its training corpus.", 
"Generally, in order to get an LLM to use tools, one must finetune it for tool-use. If the number of tools is finite, then finetuning may be done just once. If the number of tools can grow arbitrarily, as with online API services, then the LLM can be finetuned to be able to read API documentation and call API correctly.", 
"A simpler form of tool use is Retrieval Augmented Generation: augment an LLM with document retrieval, sometimes using a vector database. Given a query, a document retriever is called to retrieve the most relevant... The LLM then generates an output based on both the query and the retrieved documents.", 
"An LLM is a language model, which is not an agent as it has no goal, but it can be used as a component of an intelligent agent. Researchers have described several methods for such integrations.", 
"The ReAct ('Reason+Act') method constructs an agent out of an LLM, using the LLM as a planner. The LLM is prompted to 'think out loud'. Specifically, the language model is prompted with a textual description of the environment, a goal, a list of possible actions, and a record of the actions and observations so far. It generates one or more thoughts before generating an action, which is then executed in the environment.", 
"In the DEPS ('Describe, Explain, Plan and Select') method, an LLM is first connected to the visual world via image descriptions...", "The Reflexion method constructs an agent that learns over multiple episodes...", 
"Monte Carlo tree search can use an LLM as rollout heuristic...", "For open-ended exploration, an LLM can be used to score observations for their 'interestingness'...", "LLM-powered agents can keep a long-term memory of its previous contexts, and the memory can be retrieved in the same way as Retrieval Augmented Generation.", 
"Typically, LLM are trained with full- or half-precision floating point numbers (float32 and float16)...", "Post-training quantization aims to decrease the space requirement by lowering precision of the parameters of a trained model...", 
"Multimodality means 'having several modalities', and a 'modality' means a type of input...", "A common method to create multimodal models out of an LLM is to 'tokenize' the output of a trained encoder...", 
"Flamingo demonstrated the effectiveness of the tokenization method, finetuning a pair of pretrained language model and image encoder to perform better on visual question answering than models trained from scratch.", 
"Google PaLM model was finetuned into a multimodal model PaLM-E using the tokenization method, and applied to robotic control.", "LLaMA models have also been turned multimodal using the tokenization method, to allow image inputs, and video inputs.", 
"GPT-4 can use both text and image as inputs, while Google Gemini is expected to be multimodal.", "Mechanistic interpretability aims to reverse-engineer LLM by discovering symbolic algorithms that approximate the inference performed by LLM.", 
"One example is Othello-GPT, where a small Transformer is trained to predict legal Othello moves. It is found that there is a linear representation of Othello board, and modifying the representation changes the predicted legal Othello moves in the correct way.", 
"In another example, a small Transformer is trained on Karel programs. Similar to the Othello-GPT example, there is a linear representation of Karel program semantics, and modifying the representation changes output in the correct way. The model also generates correct programs that are on average shorter than those in the training set.", 
"In another example, the authors trained small transformers on modular arithmetic addition. The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform.", "The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform.", "Proponents of 'LLM understanding' believe that some LLM abilities, such as mathematical reasoning, imply an ability to 'understand' certain concepts.", 
"A Microsoft team argued in 2023 that GPT-4 'can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more' and that GPT-4 'could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system'.", "Some researchers characterize LLMs as 'alien intelligence'.", "For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien 'Shoggoths', and believes that RLHF tuning creates a 'smiling facade' obscuring the inner workings of the LLM.", 
"In contrast, some proponents of the 'LLMs lack understanding' school believe that existing LLMs are 'simply remixing and recombining existing writing', or point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability.", "For example, GPT-4 has natural deficits in planning and in real-time learning.", "Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed 'hallucination'.", 
"Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input.",
"Neuroscientist Terrence Sejnowski has argued that 'The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate'.", "The American Linguist George Lakoff presented Neural Theory of Language (NTL) as a computational basis for using language as a model of learning tasks and understanding.", 
"In his 2014 book titled The Language Myth: Why Language Is Not An Instinct, British cognitive linguist and digital communication technologist Vyvyan Evans maps out the role of probabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns.", 
"A large number of testing datasets and benchmarks have also been developed to evaluate the capabilities of language models on more specific downstream tasks.",
"One broad category of evaluation dataset is question answering datasets, consisting of pairs of questions and correct answers.", "A question answering task is considered 'open book' if the model's prompt includes text from which the expected answer can be derived.",
"Some examples of commonly used question answering datasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.", "Evaluation datasets may also take the form of text completion, having the model select the most likely word or sentence to complete a prompt.",
"Some composite benchmarks have also been developed which combine a diversity of different evaluation datasets and tasks. Examples include GLUE, SuperGLUE, MMLU, BIG-bench, and HELM.", "It was previously standard to report results on a heldout portion of an evaluation dataset after doing supervised fine-tuning on the remainder.", 
"It is now more common to evaluate a pre-trained model directly through prompting techniques, though researchers vary in the details of how they formulate prompts for particular tasks, particularly with respect to how many examples of solved tasks are adjoined to the prompt (i.e. the value of n in n-shot prompting).", 
"Because of the rapid pace of improvement of large language models, evaluation benchmarks have suffered from short lifespans...", "In addition, there are cases of 'shortcut learning' wherein AIs sometimes 'cheat' on multiple-choice tests...", "Some datasets have been constructed adversarially, focusing on particular problems on which extant language models seem to have unusually poor performance compared to humans.",
"One example is the TruthfulQA dataset, a question answering dataset consisting of 817 questions which language models are susceptible to answering incorrectly by mimicking falsehoods...", "Another example of an adversarial evaluation dataset is Swag and its successor, HellaSwag, collections of problems in which one of multiple options must be selected to complete a text passage.", "In 2023, Nature Biomedical Engineering wrote that 'it is no longer possible to accurately distinguish' human-written text from text created by large language models...", 
"Goldman Sachs suggested in 2023 that generative language AI could increase global GDP by 7% in the next ten years, and could expose to automation 300 million jobs globally.", "Some commenters expressed concern over accidental or deliberate creation of misinformation, or other forms of misuse."]


export default LLM_Blurb_List